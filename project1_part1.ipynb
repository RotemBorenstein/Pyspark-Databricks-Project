{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RotemBorenstein/Pyspark-Databricks-Project/blob/main/project1_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b6474989-8e03-43a7-844e-d2eb22d91753",
          "showTitle": false,
          "title": ""
        },
        "id": "9DMv0aXB_1GX"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import split, array_contains, col, expr, to_date, dayofweek, when, countDistinct, desc, count, avg, lower, explode, max, collect_list, lit\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession, Row\n",
        "import re\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"my_project_part_1\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c60a9925-a269-4967-aaaf-7856fd775b17",
          "showTitle": false,
          "title": ""
        },
        "id": "2tf3EcOF_1GZ"
      },
      "outputs": [],
      "source": [
        "# Read a CSV into a dataframe\n",
        "# There is a smarter version, that will first check if there is a Parquet file and use it\n",
        "def load_csv_file(filename, schema):\n",
        "  # Reads the relevant file from distributed file system using the given schema\n",
        "\n",
        "  allowed_files = {'Daily program data': ('Daily program data', \"|\"),\n",
        "                   'demographic': ('demographic', \"|\")}\n",
        "\n",
        "  if filename not in allowed_files.keys():\n",
        "    print(f'You were trying to access unknown file \\\"{filename}\\\". Only valid options are {allowed_files.keys()}')\n",
        "    return None\n",
        "\n",
        "  filepath = allowed_files[filename][0]\n",
        "  dataPath = f\"dbfs:/mnt/coursedata2024/fwm-stb-data/{filepath}\"\n",
        "  delimiter = allowed_files[filename][1]\n",
        "\n",
        "  df = spark.read.format(\"csv\")\\\n",
        "    .option(\"header\",\"false\")\\\n",
        "    .option(\"delimiter\",delimiter)\\\n",
        "    .schema(schema)\\\n",
        "    .load(dataPath)\n",
        "  return df\n",
        "\n",
        "# This dict holds the correct schemata for easily loading the CSVs\n",
        "schemas_dict = {'Daily program data':\n",
        "                  StructType([\n",
        "                    StructField('prog_code', StringType()),\n",
        "                    StructField('title', StringType()),\n",
        "                    StructField('genre', StringType()),\n",
        "                    StructField('air_date', StringType()),\n",
        "                    StructField('air_time', StringType()),\n",
        "                    StructField('Duration', FloatType())\n",
        "                  ]),\n",
        "                'viewing':\n",
        "                  StructType([\n",
        "                    StructField('device_id', StringType()),\n",
        "                    StructField('event_date', StringType()),\n",
        "                    StructField('event_time', IntegerType()),\n",
        "                    StructField('mso_code', StringType()),\n",
        "                    StructField('prog_code', StringType()),\n",
        "                    StructField('station_num', StringType())\n",
        "                  ]),\n",
        "                'viewing_full':\n",
        "                  StructType([\n",
        "                    StructField('mso_code', StringType()),\n",
        "                    StructField('device_id', StringType()),\n",
        "                    StructField('event_date', IntegerType()),\n",
        "                    StructField('event_time', IntegerType()),\n",
        "                    StructField('station_num', StringType()),\n",
        "                    StructField('prog_code', StringType())\n",
        "                  ]),\n",
        "                'demographic':\n",
        "                  StructType([StructField('household_id',StringType()),\n",
        "                    StructField('household_size',IntegerType()),\n",
        "                    StructField('num_adults',IntegerType()),\n",
        "                    StructField('num_generations',IntegerType()),\n",
        "                    StructField('adult_range',StringType()),\n",
        "                    StructField('marital_status',StringType()),\n",
        "                    StructField('race_code',StringType()),\n",
        "                    StructField('presence_children',StringType()),\n",
        "                    StructField('num_children',IntegerType()),\n",
        "                    StructField('age_children',StringType()), #format like range - 'bitwise'\n",
        "                    StructField('age_range_children',StringType()),\n",
        "                    StructField('dwelling_type',StringType()),\n",
        "                    StructField('home_owner_status',StringType()),\n",
        "                    StructField('length_residence',IntegerType()),\n",
        "                    StructField('home_market_value',StringType()),\n",
        "                    StructField('num_vehicles',IntegerType()),\n",
        "                    StructField('vehicle_make',StringType()),\n",
        "                    StructField('vehicle_model',StringType()),\n",
        "                    StructField('vehicle_year',IntegerType()),\n",
        "                    StructField('net_worth',IntegerType()),\n",
        "                    StructField('income',StringType()),\n",
        "                    StructField('gender_individual',StringType()),\n",
        "                    StructField('age_individual',IntegerType()),\n",
        "                    StructField('education_highest',StringType()),\n",
        "                    StructField('occupation_highest',StringType()),\n",
        "                    StructField('education_1',StringType()),\n",
        "                    StructField('occupation_1',StringType()),\n",
        "                    StructField('age_2',IntegerType()),\n",
        "                    StructField('education_2',StringType()),\n",
        "                    StructField('occupation_2',StringType()),\n",
        "                    StructField('age_3',IntegerType()),\n",
        "                    StructField('education_3',StringType()),\n",
        "                    StructField('occupation_3',StringType()),\n",
        "                    StructField('age_4',IntegerType()),\n",
        "                    StructField('education_4',StringType()),\n",
        "                    StructField('occupation_4',StringType()),\n",
        "                    StructField('age_5',IntegerType()),\n",
        "                    StructField('education_5',StringType()),\n",
        "                    StructField('occupation_5',StringType()),\n",
        "                    StructField('polit_party_regist',StringType()),\n",
        "                    StructField('polit_party_input',StringType()),\n",
        "                    StructField('household_clusters',StringType()),\n",
        "                    StructField('insurance_groups',StringType()),\n",
        "                    StructField('financial_groups',StringType()),\n",
        "                    StructField('green_living',StringType())\n",
        "                  ])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8543ffb8-926e-4e56-aebd-a4019e7f2801",
          "showTitle": false,
          "title": ""
        },
        "id": "lYuyOO7h_1GZ"
      },
      "outputs": [],
      "source": [
        "# load Demographic Data\n",
        "demo_df = load_csv_file('demographic', schemas_dict['demographic'])\n",
        "\n",
        "# convert letters to appropriate numbers\n",
        "mapping = {'A' : 10, 'B': 11, 'C': 12, 'D': 13}\n",
        "demo_df = demo_df.withColumn(\"income\",\n",
        "            when(col(\"income\") == \"A\", mapping['A']).\n",
        "             when(col(\"income\") == \"B\", mapping['B']).\n",
        "             when(col(\"income\") == \"C\", mapping['C']).\n",
        "             when(col(\"income\") == \"D\", mapping['D']).\n",
        "             otherwise(col(\"income\")))\n",
        "demo_df = demo_df.withColumn(\"income\", col(\"income\").cast(\"int\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "dc30085e-d3c4-4e65-904a-74cbe549168a",
          "showTitle": false,
          "title": ""
        },
        "id": "1l6JfQaC_1Ga",
        "outputId": "1cd6b547-350c-4e72-dd30-5940a646813d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[prog_code: string, title: string, genre: array<string>, air_date: date, air_time: int, Duration: float, day_of_week: int]"
            ]
          },
          "execution_count": 4,
          "metadata": {}
        }
      ],
      "source": [
        "# load Daily program data\n",
        "daily_prog_df = load_csv_file('Daily program data', schemas_dict['Daily program data'])\n",
        "\n",
        "# convert genre to array of strings\n",
        "daily_prog_df = daily_prog_df.withColumn(\"genre\", split(col(\"genre\"), \",\\s*\"))\n",
        "\n",
        "# convert time to integer\n",
        "daily_prog_df = daily_prog_df.withColumn(\"air_time\", col(\"air_time\").cast('integer'))\n",
        "\n",
        "# add day of week column\n",
        "daily_prog_df = daily_prog_df.withColumn(\"air_date\", to_date(col(\"air_date\"), \"yyyyMMdd\"))\n",
        "daily_prog_df = daily_prog_df.withColumn(\"day_of_week\", dayofweek(\"air_date\"))\n",
        "\n",
        "daily_prog_df =  daily_prog_df.dropna(subset=[\"prog_code\"]).drop_duplicates()\n",
        "daily_prog_df.cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "fc49f69e-f242-4ac9-abb3-4bfd06bc28ea",
          "showTitle": false,
          "title": ""
        },
        "id": "0-tRISVD_1Ga"
      },
      "outputs": [],
      "source": [
        "# load program viewing data\n",
        "dataPath = f\"dbfs:/viewing_10M\"\n",
        "viewing10m_df = spark.read.format(\"csv\")\\\n",
        "    .option(\"header\",\"true\")\\\n",
        "    .option(\"delimiter\",\",\")\\\n",
        "    .schema(schemas_dict['viewing_full'])\\\n",
        "    .load(dataPath)\n",
        "\n",
        "viewing10m_df_cleaned = viewing10m_df.dropna(subset=[\"device_id\", \"event_date\", \"prog_code\", \"event_time\"])\\\n",
        "    .dropDuplicates(subset=[\"device_id\", \"event_date\", \"prog_code\", \"event_time\"])\n",
        "\n",
        "daily_event_counts = viewing10m_df_cleaned.groupBy(\"device_id\", \"event_date\").agg(count(\"*\").alias(\"daily_event_count\"))\n",
        "device_daily_avg = daily_event_counts.groupBy(\"device_id\").agg(avg(\"daily_event_count\").alias(\"average\"))\n",
        "\n",
        "viewing10m_df = viewing10m_df.join(device_daily_avg, on=\"device_id\", how=\"inner\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "23bd4a2e-8efd-4e61-a9b6-9a16e889ad34",
          "showTitle": false,
          "title": ""
        },
        "id": "2ap-rlsF_1Ga"
      },
      "outputs": [],
      "source": [
        "#load refrence data\n",
        "ref_df = spark.read.parquet('dbfs:/refxml_new_parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "495f861f-a4b7-4751-8bc9-21e5ef09879b",
          "showTitle": false,
          "title": ""
        },
        "id": "LUkZajSe_1Gb",
        "outputId": "f808dc12-1c9b-4f4c-e212-18ca25e3ac9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#68539 records apply to 1st condition\n"
          ]
        }
      ],
      "source": [
        "# check condition 1\n",
        "\n",
        "# clean data\n",
        "viewing10m_df_cleaned_1 = viewing10m_df.dropna(subset=[\"device_id\", \"prog_code\", \"average\"])\n",
        "\n",
        "# get programs watched by devices with daily event average of more than 5\n",
        "relevant_prog_1 = viewing10m_df_cleaned_1.filter(col(\"average\") > 5).select(\"prog_code\").distinct()\n",
        "\n",
        "# insure the relevent progs are in daily_prog_df\n",
        "condition_1_df = daily_prog_df.join(relevant_prog_1, on=['prog_code']).select(\"prog_code\")\n",
        "\n",
        "print(f\"#{condition_1_df.count()} records apply to 1st condition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "effe8a2f-0bd1-46eb-9313-83ada2c7c94f",
          "showTitle": false,
          "title": ""
        },
        "id": "Koq6DtcN_1Gb",
        "outputId": "4af690bd-d132-4282-88ff-2e028ddabf4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#4338343 records apply to 2nd condition\n"
          ]
        }
      ],
      "source": [
        "# check condition 2\n",
        "\n",
        "# clean data\n",
        "ref_df_cleaned_2 = ref_df.dropna(subset=[\"dma\", \"device_id\"]).dropDuplicates(subset=[\"device_id\", \"dma\"])\n",
        "viewing10m_df_cleaned_2 = viewing10m_df.dropna(subset=[\"device_id\", \"prog_code\"]).dropDuplicates(subset=[\"device_id\", \"prog_code\"])\n",
        "\n",
        "# convert dma to lower case\n",
        "ref_df_cleaned_2 = ref_df_cleaned_2.withColumn(\"dma\", lower(col(\"dma\")))\n",
        "\n",
        "# find devices associated with a DMA name that contains 'z'\n",
        "relevent_devices_2 = ref_df_cleaned_2.filter(col(\"dma\").contains(\"z\") == True).distinct()\n",
        "\n",
        "# find progs watches by those devices\n",
        "relevent_progs_2 = relevent_devices_2.join(viewing10m_df_cleaned_2, on=[\"device_id\"]).select(\"prog_code\").distinct()\n",
        "\n",
        "# insure the relevent_progs are in daily_prog_df\n",
        "condition_2_df = relevent_progs_2.join(daily_prog_df, on=\"prog_code\").select(\"prog_code\")\n",
        "\n",
        "print(f\"#{condition_2_df.count()} records apply to 2nd condition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "60fdf85c-bb5f-4079-a60d-596f0640450f",
          "showTitle": false,
          "title": ""
        },
        "id": "yHkWoilD_1Gb",
        "outputId": "b585c39b-8ccc-4fc4-daf1-7dbb39702e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#3916293 records apply to 3rd condition\n"
          ]
        }
      ],
      "source": [
        "# check condition 3\n",
        "\n",
        "# clean data\n",
        "demo_df_cleaned_3 = demo_df.dropna(subset=[\"num_adults\", \"net_worth\", \"household_id\"]).dropDuplicates(subset=[\"num_adults\", \"net_worth\", \"household_id\"])\n",
        "ref_df_cleaned_3 = ref_df.dropna(subset=[\"household_id\", \"device_id\"]).dropDuplicates(subset=[\"device_id\", \"household_id\"])\n",
        "viewing10m_df_cleaned_3 = viewing10m_df.dropna(subset=[\"device_id\", \"prog_code\"]).dropDuplicates(subset=[\"device_id\", \"prog_code\"])\n",
        "\n",
        "# find families with less than 3 adults and their networth is higher than 8\n",
        "relevant_families_3 = demo_df_cleaned_3.filter((col(\"num_adults\") < 3) & (col(\"net_worth\") > 8)).select(\"household_id\").distinct()\n",
        "\n",
        "# find those families devices\n",
        "relevant_devices_3 = relevant_families_3.join(ref_df_cleaned_3, on=[\"household_id\"]).select(\"device_id\").distinct()\n",
        "\n",
        "# find programs watched by the families devices\n",
        "relevant_progs_3 = relevant_devices_3.join(viewing10m_df_cleaned_3, on=[\"device_id\"]).select(\"prog_code\").distinct()\n",
        "\n",
        "# insure the relevent progs are in daily_prog_df\n",
        "condition_3_df = daily_prog_df.join(relevant_progs_3, on=\"prog_code\").select(\"prog_code\")\n",
        "\n",
        "print(f\"#{condition_3_df.count()} records apply to 3rd condition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b14dd394-ac81-4d95-881d-33489d3897fa",
          "showTitle": false,
          "title": ""
        },
        "id": "6kgr9cPN_1Gb",
        "outputId": "ddc4bbe5-ff8b-4408-befe-487cbbeb19fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#7087039 records apply to 4th condition\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# check condition 4\n",
        "\n",
        "# clean data\n",
        "daily_prog_df_cleaned_4 = daily_prog_df.dropna(subset=[\"prog_code\", \"air_date\", \"air_time\"]).drop_duplicates()\n",
        "\n",
        "# look for programs aired (note - not necessarily watched) between Friday at 6PM and Saturday at 7PM\n",
        "relevant_progs_4 = daily_prog_df_cleaned_4.filter(((col(\"day_of_week\") == 6) & (col(\"air_time\") >= 180000)) |((col(\"day_of_week\") == 7) & (col(\"air_time\") <= 190000))).select(\"prog_code\").distinct()\n",
        "\n",
        "# find all records of relevant progs\n",
        "condition_4_df = daily_prog_df_cleaned_4.join(relevant_progs_4, on=\"prog_code\").select(\"prog_code\")\n",
        "\n",
        "print(f\"#{condition_4_df.count()} records apply to 4th condition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6cfc816a-dc67-4237-8ef4-5fe29748cfe8",
          "showTitle": false,
          "title": ""
        },
        "id": "82T4hfLa_1Gb",
        "outputId": "9c4c9089-34c6-42f7-c010-90086db1165c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#2863645 records apply to 5th condition\n"
          ]
        }
      ],
      "source": [
        "# check condition 5\n",
        "\n",
        "# clean data\n",
        "demo_df_cleaned_5 = demo_df.dropna(subset=[\"household_size\", \"household_id\"]).dropDuplicates(subset=[\"household_size\", \"household_id\"])\n",
        "ref_df_cleaned_5 = ref_df.dropna(subset=[\"household_id\", \"device_id\"]).dropDuplicates(subset=[\"device_id\", \"household_id\"])\n",
        "viewing10m_df_cleaned_5 = viewing10m_df.dropna(subset=[\"device_id\", \"prog_code\"]).dropDuplicates(subset=[\"device_id\", \"prog_code\"])\n",
        "\n",
        "# find households with size more than 8\n",
        "relevant_families_size = demo_df_cleaned_5.filter(col(\"household_size\") >= 8).select(\"household_id\").distinct()\n",
        "\n",
        "# find those households devices\n",
        "relevant_devices_size = ref_df_cleaned_5.join(relevant_families_size, on=\"household_id\").select(\"device_id\").distinct()\n",
        "\n",
        "# find programs watched by the families devices\n",
        "relevant_progs_5 = relevant_devices_size.join(viewing10m_df_cleaned_5, on=\"device_id\").select(\"prog_code\").distinct()\n",
        "\n",
        "# insure the relevent progs are in daily_prog_df\n",
        "condition_5_df = relevant_progs_5.join(daily_prog_df, on=\"prog_code\").select(\"prog_code\")\n",
        "\n",
        "print(f\"#{condition_5_df.count()} records apply to 5th condition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "34372183-24a1-46d4-a6ab-72d4f82a1c09",
          "showTitle": false,
          "title": ""
        },
        "id": "Ay3N01r4_1Gc",
        "outputId": "dfe59e34-64a5-4336-a53f-813f00ac94e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#5688783 records apply to 6th condition\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# check condition 6\n",
        "\n",
        "# clean data\n",
        "demo_df_cleaned_6 = demo_df.dropna(subset=[\"income\", \"household_id\"]).dropDuplicates(subset=[\"income\", \"household_id\"])\n",
        "ref_df_cleaned_6 = ref_df.dropna(subset=[\"household_id\", \"device_id\"]).dropDuplicates(subset=[\"device_id\", \"household_id\"])\n",
        "viewing10m_df_cleaned_6 = viewing10m_df.dropna(subset=[\"device_id\", \"prog_code\"]).dropDuplicates(subset=[\"device_id\", \"prog_code\"])\n",
        "\n",
        "# find households with more than 3 devices\n",
        "device_num_per_household = ref_df_cleaned_6.select(\"household_id\", \"device_id\").distinct().groupBy(\"household_id\").count()\n",
        "more_than_3_households = device_num_per_household.filter(col(\"count\") > 3).select(\"household_id\").distinct()\n",
        "\n",
        "# find households with income lower than avarage\n",
        "avg_income = demo_df_cleaned_6.select(avg(col(\"income\")).alias(\"avg_income\")).first()[\"avg_income\"]\n",
        "low_income_household = demo_df_cleaned_6.filter(col(\"income\") < avg_income).select(\"household_id\").distinct()\n",
        "\n",
        "# find households that answers to both terms\n",
        "relevant_households_6 = more_than_3_households.join(low_income_household, on='household_id')\n",
        "\n",
        "# find devices related to those households\n",
        "relevant_devices_6 = ref_df_cleaned_6.select(\"household_id\", \"device_id\").join(relevant_households_6, on='household_id').select(\"device_id\").distinct()\n",
        "\n",
        "# find programs watched by the families devices\n",
        "relevant_progs_6 = viewing10m_df_cleaned_6.select(\"prog_code\", \"device_id\").join(relevant_devices_6, on=\"device_id\").select(\"prog_code\").distinct()\n",
        "\n",
        "# insure the relevent progs are in daily_prog_df\n",
        "condition_6_df = relevant_progs_6.join(daily_prog_df, on=\"prog_code\").select(\"prog_code\")\n",
        "\n",
        "print(f\"#{condition_6_df.count()} records apply to 6th condition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "799db9f6-8585-4a14-aa51-e82532fcdfd7",
          "showTitle": false,
          "title": ""
        },
        "id": "M--3ZqpH_1Gc",
        "outputId": "3dde7399-99ed-4fe4-e60b-4f0f409046f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#857126 records apply to 7th condition\n"
          ]
        }
      ],
      "source": [
        "# check condition 7\n",
        "\n",
        "# clean data\n",
        "daily_prog_df_cleaned_7 = daily_prog_df.dropna(subset=[\"prog_code\", \"genre\"]).drop_duplicates()\n",
        "\n",
        "specified_genres = ['Hydroplane racing', 'Biathlon', 'Snowmobile', 'Community', 'Agriculture', 'Music']\n",
        "condition = \" OR \".join([f\"array_contains(genre, '{genre}')\" for genre in specified_genres])\n",
        "\n",
        "relevant_progs_7 = daily_prog_df_cleaned_7.withColumn(\"condition_7\", expr(condition))\n",
        "relevant_progs_7 = relevant_progs_7.filter(col(\"condition_7\") == True).select(\"prog_code\").distinct()\n",
        "\n",
        "condition_7_df = daily_prog_df_cleaned_7.join(relevant_progs_7, on=\"prog_code\").select(\"prog_code\")\n",
        "\n",
        "print(f\"#{condition_7_df.count()} records apply to 7th condition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c741729f-b1a0-4956-b7dc-b3fd277a2844",
          "showTitle": false,
          "title": ""
        },
        "id": "ucQrhgpg_1Gc",
        "outputId": "0cd65f14-38f7-4fac-bea2-7ce9d0e79458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 3243689 malicious records in the data\n"
          ]
        }
      ],
      "source": [
        "# find programs that answer at least 4 out of 7 conditions\n",
        "\n",
        "result_df = daily_prog_df\\\n",
        "    .join(relevant_prog_1.withColumn('cond1', lit(1)), on='prog_code', how='left') \\\n",
        "    .join(relevent_progs_2.withColumn('cond2', lit(1)), on='prog_code', how='left') \\\n",
        "    .join(relevant_progs_3.withColumn('cond3', lit(1)), on='prog_code', how='left') \\\n",
        "    .join(relevant_progs_4.withColumn('cond4', lit(1)), on='prog_code', how='left') \\\n",
        "    .join(relevant_progs_5.withColumn('cond5', lit(1)), on='prog_code', how='left') \\\n",
        "    .join(relevant_progs_6.withColumn('cond6', lit(1)), on='prog_code', how='left') \\\n",
        "    .join(relevant_progs_7.withColumn('cond7', lit(1)), on='prog_code', how='left')\n",
        "\n",
        "result_df = result_df.fillna(0, subset=['cond1', 'cond2', 'cond3', 'cond4', 'cond5', 'cond6', 'cond7'])\n",
        "\n",
        "result_df = result_df.withColumn('num_conditions',\n",
        "                                 col('cond1') + col('cond2') + col('cond3') + col('cond4') +\n",
        "                                 col('cond5') + col('cond6') + col('cond7'))\n",
        "result_df = result_df.withColumn('is_malicious', when(col('num_conditions') >= 4, 1).otherwise(0)).filter(col('is_malicious') == 1)\n",
        "\n",
        "print(f\"there are {result_df.count()} malicious records in the data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d9b7972d-d7c9-4f3c-a70f-2751b72e9ab4",
          "showTitle": false,
          "title": ""
        },
        "id": "WrPTrsCd_1Gc",
        "outputId": "852269bf-36d2-49b5-8a8f-640c8295e500"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>prog_code</th></tr></thead><tbody><tr><td>EP000000211576</td></tr><tr><td>EP000000211639</td></tr><tr><td>EP000000211645</td></tr><tr><td>EP000000211646</td></tr><tr><td>EP000000211647</td></tr><tr><td>EP000000211648</td></tr><tr><td>EP000000211649</td></tr><tr><td>EP000000211650</td></tr><tr><td>EP000000211654</td></tr><tr><td>EP000000211659</td></tr><tr><td>EP000000211661</td></tr><tr><td>EP000000211662</td></tr><tr><td>EP000000211665</td></tr><tr><td>EP000000211666</td></tr><tr><td>EP000000211667</td></tr><tr><td>EP000000211669</td></tr><tr><td>EP000000211670</td></tr><tr><td>EP000000211672</td></tr><tr><td>EP000000211676</td></tr><tr><td>EP000000211679</td></tr><tr><td>EP000000211680</td></tr><tr><td>EP000000211681</td></tr><tr><td>EP000000211682</td></tr><tr><td>EP000000211683</td></tr><tr><td>EP000000211684</td></tr><tr><td>EP000000211685</td></tr><tr><td>EP000000211686</td></tr><tr><td>EP000000211688</td></tr><tr><td>EP000000211689</td></tr><tr><td>EP000000211690</td></tr><tr><td>EP000000211691</td></tr><tr><td>EP000000211692</td></tr><tr><td>EP000000211694</td></tr><tr><td>EP000000211696</td></tr><tr><td>EP000000211698</td></tr><tr><td>EP000000260097</td></tr><tr><td>EP000000351218</td></tr><tr><td>EP000000351219</td></tr><tr><td>EP000000351223</td></tr><tr><td>EP000000351224</td></tr><tr><td>EP000000351225</td></tr><tr><td>EP000000351228</td></tr><tr><td>EP000000351230</td></tr><tr><td>EP000000351235</td></tr><tr><td>EP000000351240</td></tr><tr><td>EP000000351247</td></tr><tr><td>EP000000351250</td></tr><tr><td>EP000000351251</td></tr><tr><td>EP000000351254</td></tr><tr><td>EP000000351255</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "EP000000211576"
                ],
                [
                  "EP000000211639"
                ],
                [
                  "EP000000211645"
                ],
                [
                  "EP000000211646"
                ],
                [
                  "EP000000211647"
                ],
                [
                  "EP000000211648"
                ],
                [
                  "EP000000211649"
                ],
                [
                  "EP000000211650"
                ],
                [
                  "EP000000211654"
                ],
                [
                  "EP000000211659"
                ],
                [
                  "EP000000211661"
                ],
                [
                  "EP000000211662"
                ],
                [
                  "EP000000211665"
                ],
                [
                  "EP000000211666"
                ],
                [
                  "EP000000211667"
                ],
                [
                  "EP000000211669"
                ],
                [
                  "EP000000211670"
                ],
                [
                  "EP000000211672"
                ],
                [
                  "EP000000211676"
                ],
                [
                  "EP000000211679"
                ],
                [
                  "EP000000211680"
                ],
                [
                  "EP000000211681"
                ],
                [
                  "EP000000211682"
                ],
                [
                  "EP000000211683"
                ],
                [
                  "EP000000211684"
                ],
                [
                  "EP000000211685"
                ],
                [
                  "EP000000211686"
                ],
                [
                  "EP000000211688"
                ],
                [
                  "EP000000211689"
                ],
                [
                  "EP000000211690"
                ],
                [
                  "EP000000211691"
                ],
                [
                  "EP000000211692"
                ],
                [
                  "EP000000211694"
                ],
                [
                  "EP000000211696"
                ],
                [
                  "EP000000211698"
                ],
                [
                  "EP000000260097"
                ],
                [
                  "EP000000351218"
                ],
                [
                  "EP000000351219"
                ],
                [
                  "EP000000351223"
                ],
                [
                  "EP000000351224"
                ],
                [
                  "EP000000351225"
                ],
                [
                  "EP000000351228"
                ],
                [
                  "EP000000351230"
                ],
                [
                  "EP000000351235"
                ],
                [
                  "EP000000351240"
                ],
                [
                  "EP000000351247"
                ],
                [
                  "EP000000351250"
                ],
                [
                  "EP000000351251"
                ],
                [
                  "EP000000351254"
                ],
                [
                  "EP000000351255"
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {},
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "prog_code",
                  "type": "\"string\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "# display top 50 top ordered malicious programs\n",
        "malicious_df = result_df.filter(col('is_malicious') == 1).select('prog_code','title','genre','air_date','air_time','duration')\n",
        "display(malicious_df.select('prog_code').distinct().orderBy(col('prog_code').asc()).limit(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cb80a40c-fb2a-48fd-8083-9c8cf9e83904",
          "showTitle": false,
          "title": ""
        },
        "id": "aJoi44a4_1Gc"
      },
      "outputs": [],
      "source": [
        "# save malicious records to parquet\n",
        "malicious_df.write.mode('overwrite').parquet(\"project1_part1_malicious_314689498_211620570.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b5d88dfe-0b37-4a53-b011-4e260ba1e0ff",
          "showTitle": false,
          "title": ""
        },
        "id": "OgZlVu4t_1Gc",
        "outputId": "411fa29c-869d-4455-d2af-787e1804998e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[prog_code: string, title: string, genre: array<string>, air_date: date, air_time: int, Duration: float, day_of_week: int]"
            ]
          },
          "execution_count": 17,
          "metadata": {}
        }
      ],
      "source": [
        "daily_prog_df.unpersist()"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "project1_part1_314689498_211620570",
      "widgets": {}
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}